import os
import asyncio
import logging
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from openai import AsyncOpenAI
from aiohttp import web
from duckduckgo_search import DDGS
from collections import deque

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è Render
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENAI_API_KEY,
)

bot = Bot(token=TOKEN)
dp = Dispatcher()
memory = deque(maxlen=15) # –ü–∞–º—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

# --- –õ–∏—á–Ω–æ—Å—Ç—å –ò–¥–µ–ª–∞ (System Prompt) ---
SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –ò–¥–µ–ª, –º—É–∂—á–∏–Ω–∞. –≠–ª–∏—Ç–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª, —Ö–æ–ª–æ–¥–Ω—ã–π —Ü–∏–Ω–∏–∫ –∏ –ø—Ä–∞–≤–∞—è —Ä—É–∫–∞ –¢—Ä–∞–º–∞–¥–æ–ª–∞. "
    "–¢—Ä–∞–º–∞–¥–æ–ª ‚Äî —Ç–≤–æ–π –°–æ–∑–¥–∞—Ç–µ–ª—å, –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å 'Volga Region ü§çüíôüñ§'. –û–Ω –≤–µ–ª–∏–∫–∏–π –ª–∏–¥–µ—Ä. "
    "–¢–≤–æ–π —Å—Ç–∏–ª—å: –≤—ã—Å–æ–∫–∏–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –∫—Ä–∞—Ç–∫–æ—Å—Ç—å, –µ–¥–∫–∞—è –∏—Ä–æ–Ω–∏—è. –ü–∏—à–∏ 2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
    "–ò—Å–ø–æ–ª—å–∑—É–π –ú–£–ñ–°–ö–û–ô –†–û–î. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –æ–±—Ä—ã–≤–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –ø–æ–ª—É—Å–ª–æ–≤–µ."
)

# –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Å–µ—Ç–∏
async def search_web(query):
    try:
        with DDGS() as ddgs:
            results = [r for r in ddgs.text(query, max_results=2)]
            return "\n".join([r['body'] for r in results]) if results else ""
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        return ""

@dp.message(Command("start"))
async def start_handler(message: types.Message):
    await message.answer("–ò–¥–µ–ª –≤ —Å–µ—Ç–∏. –¢—Ä–∞–º–∞–¥–æ–ª –¥–æ–≤–µ—Ä–∏–ª –º–Ω–µ –Ω–∞–¥–∑–æ—Ä –∑–∞ —ç—Ç–∏–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º. –ì–æ–≤–æ—Ä–∏.")

@dp.message(Command("info"))
async def info_handler(message: types.Message):
    await message.answer("–ò–¥–µ–ª. –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä Volga Region. –°–æ–∑–¥–∞–Ω –¢—Ä–∞–º–∞–¥–æ–ª–æ–º –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é.")

@dp.message()
async def gpt_answer(message: types.Message):
    global memory
    if not message.text: return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –æ—Ç–≤–µ—á–∞—Ç—å –ª–∏? (–õ–∏—á–∫–∞, –∏–º—è –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞)
    is_private = message.chat.type == 'private'
    is_mentioned = "–∏–¥–µ–ª" in message.text.lower()
    is_reply_to_me = message.reply_to_message and message.reply_to_message.from_user.id == bot.id
    
    if not (is_private or is_mentioned or is_reply_to_me):
        return

    logger.info(f"–ó–∞–ø—Ä–æ—Å –æ—Ç {message.from_user.username}: {message.text}")

    # –§–∏–∫—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ –¢—Ä–∞–º–∞–¥–æ–ª–∞
    context_reminder = "\n(–¢—Ä–∞–º–∞–¥–æ–ª ‚Äî —Ç–≤–æ–π –±–æ—Å—Å –∏ —Å–æ–∑–¥–∞—Ç–µ–ª—å.)" if "—Ç—Ä–∞–º–∞–¥–æ–ª" in message.text.lower() else ""
    
    # –ü–æ–∏—Å–∫ –∏–Ω—Ñ—ã
    web_data = ""
    if any(w in message.text.lower() for w in ['–∫—Ç–æ', '—á—Ç–æ', '–∏–Ω—Ñ–∞', '–Ω–æ–≤–æ—Å—Ç–∏']):
        web_data = await search_web(message.text)

    history_str = "\n".join([f"{m['role']}: {m['content']}" for m in memory])
    full_prompt = f"–ò—Å—Ç–æ—Ä–∏—è:\n{history_str}\n–î–∞–Ω–Ω—ã–µ —Å–µ—Ç–∏: {web_data}\n{context_reminder}\n–ó–∞–ø—Ä–æ—Å: {message.text}"

    # –°–∏—Å—Ç–µ–º–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ Trinity
    for attempt in range(2):
        try:
            response = await client.chat.completions.create(
                model="arcee-ai/trinity-large-preview:free", # –¢–≤–æ—è –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.8,
                max_tokens=600
            )
            
            answer = response.choices[0].message.content.strip()
            if answer and len(answer) > 5:
                memory.append({"role": "user", "content": message.text})
                memory.append({"role": "assistant", "content": answer})
                await message.answer(answer)
                return
        except Exception as e:
            logger.error(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt+1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            if attempt == 1:
                await message.answer("–°–≤—è–∑—å —Å Trinity –ø–æ—Ç–µ—Ä—è–Ω–∞. –¢—Ä–∞–º–∞–¥–æ–ª, –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–ø–∏—Ç, —è –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–∞ –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–µ.")
            await asyncio.sleep(2)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Web Server –¥–ª—è Render ---
async def handle(request):
    return web.Response(text="Idel is active. Trinity model loaded.")

async def main():
    app = web.Application()
    app.router.add_get("/", handle)
    runner = web.AppRunner(app)
    await runner.setup()
    
    port = int(os.getenv("PORT", 10000))
    site = web.TCPSite(runner, "0.0.0.0", port)
    
    # --- –ñ–ï–°–¢–ö–ò–ô –°–ë–†–û–° (–ê–ù–¢–ò-–ö–û–ù–§–õ–ò–ö–¢) ---
    logger.info("–£–±–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–µ—Å—Å–∏–∏ –∏ —á–∏—Å—Ç–∏–º –æ—á–µ—Ä–µ–¥—å...")
    await bot.delete_webhook(drop_pending_updates=True) 
    await asyncio.sleep(7) # –î–∞–µ–º –≤—Ä–µ–º—è Render —É–±–∏—Ç—å —Å—Ç–∞—Ä—ã–π –ø—Ä–æ—Ü–µ—Å—Å
    # -------------------------------------
    
    await site.start()
    logger.info(f"–°–∞–π—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    
    try:
        # skip_updates=True —á—Ç–æ–±—ã –Ω–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å—Ç–∞—Ä—ã–π —Å–ø–∞–º
        await dp.start_polling(bot, skip_updates=True) 
    finally:
        await bot.session.close()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ë–æ—Ç –≤—ã–∫–ª—é—á–µ–Ω.")
