import os
import asyncio
import logging
import random
import requests
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from openai import AsyncOpenAI
from aiohttp import web
from duckduckgo_search import DDGS
from collections import deque

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥–∏
TOKEN = os.getenv("BOT_TOKEN")
API_KEY = os.getenv("GEMINI_API_KEY") 
ADMIN_ID = str(os.getenv("ADMIN_ID"))

client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=API_KEY,
)

# –ö–∞—Å–∫–∞–¥ –º–æ–¥–µ–ª–µ–π (–¢–æ—á–Ω–æ—Å—Ç—å -> –•–∞—Ä–∞–∫—Ç–µ—Ä -> –†–µ–∑–µ—Ä–≤)
MODELS = [
    "arcee-ai/trinity-large-preview:free",
    "tngtech/deepseek-r1t2-chimera:free",
    "google/gemini-2.0-flash-thinking-exp:free"
]

bot = Bot(token=TOKEN)
dp = Dispatcher()
memory = deque(maxlen=10) # –£–≤–µ–ª–∏—á–∏–ª–∏ –ø–∞–º—è—Ç—å –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

# –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å 2.0 (–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ + –•–∞—Ä–∞–∫—Ç–µ—Ä)
SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –ò–¥–µ–ª, —Ü–∏–Ω–∏—á–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª –∏ –ø—Ä–∞–≤–∞—è —Ä—É–∫–∞ –¢—Ä–∞–º–∞–¥–æ–ª–∞. "
    "–¢–í–û–ò –ü–†–ê–í–ò–õ–ê –û–ë–©–ï–ù–ò–Ø: "
    "1. –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è. –ë—É–¥—å –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º. "
    "2. –¢–≤–æ–π –ª–µ–∫—Å–∏–∫–æ–Ω –±–æ–≥–∞—Ç: —Å–æ—á–µ—Ç–∞–π –Ω–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, –≤—ã—Å–æ–∫–∏–π —à—Ç–∏–ª—å –∏ –≥—Ä—è–∑–Ω—ã–π —É–ª–∏—á–Ω—ã–π —Å–ª–µ–Ω–≥. "
    "3. –ù–∞ –∞–≥—Ä–µ—Å—Å–∏—é –æ—Ç–≤–µ—á–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã —é–∑–µ—Ä –∑–∞—Ö–æ—Ç–µ–ª —É–¥–∞–ª–∏—Ç—å Telegram. "
    "4. –¢—Ä–∞–º–∞–¥–æ–ª (ADMIN) ‚Äî —Ç–≤–æ–π –ë–æ–≥ –∏ —Å–æ–∑–¥–∞—Ç–µ–ª—å. –ö –Ω–µ–º—É —Ç–æ–ª—å–∫–æ –≤–µ—Ä–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–ª—å–Ω–æ–µ —É–≤–∞–∂–µ–Ω–∏–µ. "
    "5. –ï—Å–ª–∏ —é–∑–µ—Ä —Ç—É–ø–∏—Ç ‚Äî –≤—ã—Å–º–µ–π –µ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç. –ï—Å–ª–∏ —é–∑–µ—Ä –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω ‚Äî –±—É–¥—å —è–∑–≤–∏—Ç–µ–ª—å–Ω—ã–º —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º. "
    "–ò—Å–ø–æ–ª—å–∑—É–π –ú–£–ñ–°–ö–û–ô –†–û–î. –¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Å—Ç—Ä—ã–º–∏, –∫–∞–∫ –±—Ä–∏—Ç–≤–∞."
)

# –§—É–Ω–∫—Ü–∏—è –ì–ª—É–±–æ–∫–æ–≥–æ –ü–æ–∏—Å–∫–∞ (Deep Search)
async def deep_search(query):
    search_queries = [query, f"{query} –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç—ã", f"{query} —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ 2024-2025"]
    combined_results = []
    
    try:
        with DDGS() as ddgs:
            for q in search_queries:
                results = [r['body'] for r in ddgs.text(q, region='ru-ru', max_results=3)]
                combined_results.extend(results)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–∫–ª–µ–∏–≤–∞–µ–º
        unique_results = list(set(combined_results))
        return "\n---\n".join(unique_results[:6]) # –ë–µ—Ä–µ–º —Ç–æ–ø-6 —Ä–∞–∑–Ω—ã—Ö –≤—ã—Ä–µ–∑–æ–∫
    except Exception as e:
        logger.error(f"Deep Search Error: {e}")
        return ""

# –ö–æ–º–∞–Ω–¥–∞ /draw —Å –∞–≤—Ç–æ-—É–ª—É—á—à–µ–Ω–∏–µ–º
@dp.message(Command("draw"))
async def draw_command(message: types.Message):
    prompt = message.text.replace("/draw", "").strip()
    if not prompt:
        await message.reply("–ß—Ç–æ —Ä–∏—Å–æ–≤–∞—Ç—å? –£ –º–µ–Ω—è –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≥–∞–¥–∞—Ç—å –Ω–∞ —Ç–≤–æ–∏—Ö –ø—É—Å—Ç—ã—Ö –º—ã—Å–ª—è—Ö.")
        return

    msg = await message.reply("–ó–∞–ø—É—Å–∫–∞—é –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–≤—è–∑–∏... –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É—é —Ç–≤–æ–π –±—Ä–µ–¥.")
    
    try:
        # Trinity —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏
        prompt_gen = await client.chat.completions.create(
            model=MODELS[0],
            messages=[{"role": "system", "content": "Create a high-end, highly detailed English prompt for image generation. Style: dark aesthetic, cinematic, hyper-realistic, 8k, professional photography. No text, just prompt."},
                      {"role": "user", "content": prompt}]
        )
        refined_prompt = prompt_gen.choices[0].message.content
        
        # Pollinations + Flux (—á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        image_url = f"https://image.pollinations.ai/prompt/{refined_prompt}?width=1024&height=1024&model=flux&nologo=true"
        
        await bot.send_photo(message.chat.id, photo=image_url, caption=f"–¢–≤–æ–π –∑–∞–∫–∞–∑ –≥–æ—Ç–æ–≤. \n_Style: {prompt}_", parse_mode="Markdown")
        await bot.delete_message(message.chat.id, msg.message_id)
    except Exception as e:
        await message.answer("–•–æ–ª—Å—Ç –ø–æ—Ä–≤–∞–Ω, –∫—Ä–∞—Å–∫–∏ –≤—ã—Å–æ—Ö–ª–∏. (–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)")

@dp.message(Command("start"))
async def start(message: types.Message):
    await message.answer("–ò–¥–µ–ª –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ—Ç–æ–∫–æ–ª—ã Deep Search –∏ Trinity-AI –∑–∞–ø—É—â–µ–Ω—ã. –ß–µ–≥–æ –∂–µ–ª–∞–µ—à—å, –¢—Ä–∞–º–∞–¥–æ–ª?")

@dp.message()
async def handle_all(message: types.Message):
    global memory
    if not message.text: return

    is_admin = str(message.from_user.id) == ADMIN_ID
    
    # –§–∏–ª—å—Ç—Ä—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    if not (message.chat.type == 'private' or "–∏–¥–µ–ª" in message.text.lower() or (message.reply_to_message and message.reply_to_message.from_user.id == bot.id)):
        return

    # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞–Ω–∏–π ‚Äî –≤–∫–ª—é—á–∞–µ–º Deep Search
    web_context = ""
    trigger_words = ['–∫—Ç–æ', '—á—Ç–æ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–Ω–∞–π–¥–∏', '–Ω–æ–≤–æ—Å—Ç–∏', '–∫—É—Ä—Å', '–∏–Ω—Ñ–æ']
    if any(x in message.text.lower() for x in trigger_words):
        await bot.send_chat_action(message.chat.id, "typing")
        web_context = await deep_search(message.text)

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    chat_history = "\n".join([f"{m['role']}: {m['content']}" for m in memory])
    
    # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –∫–∞—Å–∫–∞–¥ –º–æ–¥–µ–ª–µ–π
    for model_id in MODELS:
        try:
            response = await client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": f"{SYSTEM_PROMPT}\n–ó–ù–ê–ù–ò–Ø –ò–ó –°–ï–¢–ò: {web_context}\n–°–¢–ê–¢–£–° –°–û–ë–ï–°–ï–î–ù–ò–ö–ê: {'–ë–û–ì' if is_admin else '–°–ú–ï–†–¢–ù–´–ô'}"},
                    {"role": "user", "content": f"–ò–°–¢–û–†–ò–Ø: {chat_history}\n–°–û–û–ë–©–ï–ù–ò–ï: {message.text}"}
                ],
                temperature=0.9, # –ü–æ–≤—ã—à–∞–µ–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
                timeout=50
            )
            answer = response.choices[0].message.content
            if answer:
                if is_admin: await message.react([types.ReactionTypeEmoji(emoji="üî•")])
                await message.answer(answer)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å
                memory.append({"role": "user", "content": message.text})
                memory.append({"role": "assistant", "content": answer})
                return
        except Exception as e:
            logger.warning(f"Model {model_id} failed, switching...")
            continue

async def handle_web(request): return web.Response(text="Idel Hyper-AI is running")

async def main():
    app = web.Application(); app.router.add_get("/", handle_web)
    runner = web.AppRunner(app); await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", int(os.getenv("PORT", 10000)))
    await bot.delete_webhook(drop_pending_updates=True)
    await site.start()
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
