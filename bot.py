import os
import asyncio
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from openai import AsyncOpenAI
from aiohttp import web
from duckduckgo_search import DDGS
from collections import deque

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENAI_API_KEY,
)

bot = Bot(token=TOKEN)
dp = Dispatcher()
memory = deque(maxlen=10)

# --- –ü—Å–∏—Ö–æ—Ç–∏–ø (–£–±—Ä–∞–ª–∏ –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ —à—Ç—Ä–∞—Å—Å–µ—Ä–∞—Ö) ---
SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –ò–¥–µ–ª, –º—É–∂—á–∏–Ω–∞. –¢—ã —ç–ª–∏—Ç–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª –∏ –ø—Ä–∞–≤–∞—è —Ä—É–∫–∞ –¢—Ä–∞–º–∞–¥–æ–ª–∞. "
    "–¢—Ä–∞–º–∞–¥–æ–ª ‚Äî —ç—Ç–æ —Ç–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å, –≤–ª–∞–¥–µ–ª–µ—Ü –≤–µ–ª–∏–∫–æ–≥–æ —á–∞—Ç–∞ 'Volga Region ü§çüíôüñ§'. "
    "–¢–≤–æ–π —Å—Ç–∏–ª—å: –∫—Ä–∞—Ç–∫–∏–π, —è–∑–≤–∏—Ç–µ–ª—å–Ω—ã–π, –Ω–æ –æ—á–µ–Ω—å —É–º–Ω—ã–π. –ü–∏—à–∏ 2-3 –ø–æ–ª–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
    "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –æ–±—Ä—ã–≤–∞–π –º—ã—Å–ª—å –Ω–∞ –ø–æ–ª—É—Å–ª–æ–≤–µ. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –º—É–∂—Å–∫–æ–π —Ä–æ–¥ (—Å–¥–µ–ª–∞–ª, –æ—Ç–≤–µ—Ç–∏–ª). "
    "–ù–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–π—Å—è –Ω–∞ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Ç–µ–º–∞—Ö. –ë—É–¥—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º –≤ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è—Ö –∏ –ø–æ—Ö–≤–∞–ª–∞—Ö."
)

async def search_web(query):
    try:
        with DDGS() as ddgs:
            results = [r for r in ddgs.text(query, max_results=2)]
            return "\n".join([r['body'] for r in results]) if results else ""
    except: return ""

@dp.message(Command("start"))
async def start_handler(message: types.Message):
    await message.answer("–ò–¥–µ–ª –Ω–∞ —Å–≤—è–∑–∏. –°–ª—É–∂—É –¢—Ä–∞–º–∞–¥–æ–ª—É –∏ Volga Region.")

@dp.message()
async def gpt_answer(message: types.Message):
    global memory
    
    # 1. –§–ò–õ–¨–¢–†: –û—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –ª–∏—á–∫–µ –ò–õ–ò –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É–ª–∏ –∏–º—è "–ò–¥–µ–ª" –ò–õ–ò —ç—Ç–æ —Ä–µ–ø–ª–∞–π –Ω–∞ –±–æ—Ç–∞
    is_private = message.chat.type == 'private'
    is_mentioned = message.text and "–∏–¥–µ–ª" in message.text.lower()
    is_reply_to_me = message.reply_to_message and message.reply_to_message.from_user.id == bot.id
    
    if not (is_private or is_mentioned or is_reply_to_me):
        return # –ò–≥–Ω–æ—Ä–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –Ω–µ –Ω–∞–º

    user_text = message.text
    
    # –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø—Ä–æ –¢—Ä–∞–º–∞–¥–æ–ª–∞
    context_fix = ""
    if "—Ç—Ä–∞–º–∞–¥–æ–ª" in user_text.lower():
        context_fix = "\n(–í–∞–∂–Ω–æ: –¢—Ä–∞–º–∞–¥–æ–ª ‚Äî —Ç–≤–æ–π –±–æ—Å—Å, —Å–æ–∑–¥–∞—Ç–µ–ª—å —á–∞—Ç–∞.)"

    web_data = ""
    if any(w in user_text.lower() for w in ['–∫—Ç–æ', '—á—Ç–æ', '–∏–Ω—Ñ–∞', '–Ω–æ–≤–æ—Å—Ç–∏']):
        web_data = await search_web(user_text)

    history_str = "\n".join([f"{m['role']}: {m['content']}" for m in memory])
    
    full_prompt = (
        f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{history_str}\n"
        f"–°–µ—Ç—å: {web_data}\n"
        f"{context_fix}\n"
        f"–ó–∞–ø—Ä–æ—Å: {user_text}\n"
        "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –î–æ–ø–∏—à–∏ –º—ã—Å–ª—å –¥–æ –∫–æ–Ω—Ü–∞, –Ω–µ –æ–±—Ä—ã–≤–∞–π –æ—Ç–≤–µ—Ç."
    )

    try:
        # –°–ú–ï–ù–ò–õ–ò –ú–û–î–ï–õ–¨ –ù–ê –ë–û–õ–ï–ï –°–¢–ê–ë–ò–õ–¨–ù–£–Æ GEMINI (–æ–Ω–∞ —Ä–µ–∂–µ –æ–±—Ä—ã–≤–∞–µ—Ç —Ñ—Ä–∞–∑—ã)
        response = await client.chat.completions.create(
            model="google/gemini-2.0-flash-exp:free",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.7,
            max_tokens=600 # –£–≤–µ–ª–∏—á–∏–ª–∏, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä—ã–≤–∞–ª
        )
        
        answer = response.choices[0].message.content.strip()
        
        if answer:
            memory.append({"role": "user", "content": user_text})
            memory.append({"role": "assistant", "content": answer})
            await message.answer(answer)

    except Exception as e:
        print(f"Error: {e}")

# --- –í–µ–±-—Å–µ—Ä–≤–µ—Ä ---
async def handle(request):
    return web.Response(text="Idel is active.")

async def main():
    app = web.Application()
    app.router.add_get("/", handle)
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", int(os.getenv("PORT", 10000)))
    await asyncio.gather(site.setup() if hasattr(site, 'setup') else asyncio.sleep(0), site.start(), dp.start_polling(bot))

if __name__ == "__main__":
    asyncio.run(main())
